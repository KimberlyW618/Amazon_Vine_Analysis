{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V58rxea0HqSa",
    "outputId": "f07c0baf-61fb-454f-aa9b-ed0cc4bdb477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('enjoy', 'VBP'), ('biking', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('trails', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "# Natural Language\n",
    "# Part-of-Speech Tagging > A process in NLP where you can find key pieces of grammar information for each word.\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "text = word_tokenize(\"I enjoy biking on the trails\")\n",
    "output = nltk.pos_tag(text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xKwTpATHqSe",
    "outputId": "c94dd48c-b2e1-4ac3-f18a-77c21336d1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('love', 'VBP'), ('snuggling', 'VBG'), ('with', 'IN'), ('my', 'PRP$'), ('puppy', 'JJ'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "text = word_tokenize(\"I love snuggling with my puppy.\")\n",
    "output = nltk.pos_tag(text)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Analyses\n",
    "There are three types of NLP analyses:\n",
    "\n",
    "- Syntactic analysis is essentially checking the dictionary definition of each element of a sentence or document. In this type of analysis, we don't care about the words that come before or after the word in questionâ€”we just care about the given word.\n",
    "- Sentiment analysis pertains to what the text means. Is it positive, negative, or neutral? You can come up with a score of how positive or negative the text is using NLP.\n",
    "- Semantic analysis entails extracting the meaning of the text. You want to analyze the meaning of each word, and then relate that to the meaning of the text as a whole.\n",
    "\n",
    "\n",
    "Each step of the NLP pipeline involves a separate task. The output data from one step, in turn, becomes the input data for the next step, with an opportunity to evaluate and refine each task, if needed. A basic NLP pipeline follows:\n",
    "\n",
    "1. Raw Text: Start with the raw data.\n",
    "2. Tokenization: Separate the words from paragraphs or sentences, into individual words.\n",
    "3. Stop Words Filtering: Remove common words like \"a\" and \"the\" that add no real value to what we are looking to analyze.\n",
    "4. Term Frequency-Inverse Document Frequency (TF-IDF): Statistically rank the words by importance compared to the rest of the words in the text. This is also when the words are converted from text to numbers.\n",
    "5. Machine Learning: Put everything together and run through the machine learning model to produce an output.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMqDAjVS0KN9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Exuo6ebUsCqW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Amazon_Reviews_ETL_starter_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
